{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1zjoyiYY8eSHUFBXQrEk5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jhansipothabattula/Machine_Learning/blob/main/Day42.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "BRkkor8ZxQiE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parameters and Hypeparameters**\n",
        "\n",
        "- What are Parameters?\n",
        "\n",
        "  - values are learned by a machine learning model during training\n",
        "\n",
        "  - adjusted to min the loss function and optimize predictions\n",
        "\n",
        "  - Examples:\n",
        "\n",
        "    - Coefficients in Linear Regression\n",
        "\n",
        "    - Weights and biases in Neural Networks\n",
        "\n",
        "- What are Hyperparameters?\n",
        "\n",
        "  - Settings defined before training that influence how the model learns from data\n",
        "\n",
        "  - Not Learned from the data but instead control the training process\n",
        "\n",
        "  - Examples\n",
        "\n",
        "    - Tree Depth\n",
        "\n",
        "    - Learning Rate\n",
        "\n",
        "    - Number of Estimators"
      ],
      "metadata": {
        "id": "wq-n_kT7xX1l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importance of Tuning Hyperparameters**\n",
        "\n",
        "- Why Tune Hyperparameters?\n",
        "\n",
        "  - Improve Model Perfomance\n",
        "\n",
        "    - Optimal Hyperparameters help models generalizes better, reducing overfitting and underfitting\n",
        "\n",
        "  - Enhance Efficiency\n",
        "\n",
        "    - Proper Tuning can reduce training time and computational resources\n",
        "\n",
        "  - Adapt Problem-Specific Needs\n",
        "\n",
        "    - Tailoring hyperparameters ensures the mocel fits the dataset's characterestics"
      ],
      "metadata": {
        "id": "6xXHPPo8yPE2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Common Hyperparameters in popular Models**\n",
        "\n",
        "- Decision Trees and Random Forests\n",
        "\n",
        "  - max-Depth: Limits the depth of trees to avoid overfitting\n",
        "\n",
        "  - Min samples models: Minimum samples required to split an internal node\n",
        "\n",
        "  - Number of Estimators: Total Numbe of trees in Random Forest\n",
        "\n",
        "- Gradient Boosting Models:\n",
        "\n",
        "  - Learning Rate: Determines the contribution of each tree\n",
        "\n",
        "  - Subsample: Fraction of training data used to train each tree\n",
        "\n",
        "  - Max Depth: Limits the complexity of individual trees\n",
        "\n",
        "- Neural Networks\n",
        "\n",
        "  - Learning Rate: Step size for weights updates\n",
        "  \n",
        "  - Number of Layers: Determines the depth of the Network\n",
        "\n",
        "  - batch Size: Number of samples per gradient update"
      ],
      "metadata": {
        "id": "G-ym0xRkzMTc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objective**\n",
        "\n",
        "- Train a model with default hyperparameters, evaluate it's perfomance and manually adjust a few hyperparameters to observe their impact on results"
      ],
      "metadata": {
        "id": "Pntb6jRj0JDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Display dataset info\n",
        "print(f\"Feature Names: \\n{data.feature_names}\")\n",
        "print(f\"Class names: \\n{data.target_names}\")\n",
        "\n",
        "# Train Random Forest with default hyperparameters\n",
        "rf_default = RandomForestClassifier(random_state=42)\n",
        "rf_default.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_default = rf_default.predict(X_test)\n",
        "accuracy_default = accuracy_score(y_test, y_pred_default)\n",
        "\n",
        "print(f\"Default Model Accuracy: {accuracy_default:.4f}\")\n",
        "print(\"Classification Report:\", classification_report(y_test, y_pred_default))\n",
        "\n",
        "# Train Random Forest with adjusted parameters\n",
        "rf_tuned = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=5,\n",
        "    random_state=42\n",
        ")\n",
        "rf_tuned.fit(X_train, y_train)\n",
        "\n",
        "# Predict and Evaluate\n",
        "y_pred_tuned = rf_tuned.predict(X_test)\n",
        "accuracy_tuned = accuracy_score(y_test, y_pred_tuned)\n",
        "\n",
        "print(f\"Tuned Model Accuracy: {accuracy_tuned:.4f}\")\n",
        "print(\"Classification Report\", classification_report(y_test, y_pred_tuned))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-Rj8QPm0aNB",
        "outputId": "08db9474-0fe6-4c35-a946-a99b5f3d91d6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Names: \n",
            "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
            "Class names: \n",
            "['setosa' 'versicolor' 'virginica']\n",
            "Default Model Accuracy: 1.0000\n",
            "Classification Report:               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n",
            "Tuned Model Accuracy: 1.0000\n",
            "Classification Report               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n"
          ]
        }
      ]
    }
  ]
}