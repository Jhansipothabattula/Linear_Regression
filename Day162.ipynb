{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdJdK9PZjPpvHb9AMthEIf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jhansipothabattula/Data_Science/blob/main/Day162.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Debugging and Troubleshooting"
      ],
      "metadata": {
        "id": "9CfyveX5NsLj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **Introduction**\n",
        "\n",
        "* Even with well-structured code, issues can arise during the development of deep learning models.\n",
        "* Debugging and troubleshooting are essential skills for identifying and resolving errors, improving model stability, and optimizing performance.\n",
        "* In this section, we will explore common errors and warnings in PyTorch, effective debugging techniques, strategies for handling numerical stability issues like NaNs and infinities, and tools for profiling and optimizing PyTorch code.\n",
        "* By mastering these skills, you can ensure your models run smoothly and efficiently in both development and production environments.\n",
        "\n",
        "\n",
        " **Understanding Common PyTorch Errors and Warnings**\n",
        "\n",
        "### **Common Errors**\n",
        "\n",
        "* **Shape Mismatch Errors:** These occur when operations are performed on tensors with incompatible shapes. Common examples include trying to add tensors of different dimensions or incorrectly defining model layers.\n",
        "* **Example:** `RuntimeError: The size of tensor a (10) must match the size of tensor b (12) at non-singleton dimension 0`\n",
        "* **Solution:** Check the shapes of the tensors involved using `tensor.shape` and ensure they are compatible for the intended operation.\n",
        "\n",
        "\n",
        "* **Type Errors:** PyTorch operations are sensitive to tensor data types. A common mistake is performing operations between tensors of different types, such as float32 and int64.\n",
        "* **Example:** `RuntimeError: Expected object of scalar type Float but got scalar type Long for argument #2 'weight'`\n",
        "* **Solution:** Ensure tensors are of the same type using `tensor.type()` and convert them if necessary using `tensor.float()` or `tensor.long()`.\n",
        "\n",
        "\n",
        "* **CUDA Errors:** These errors are related to GPU usage and occur when operations are performed on tensors that are not on the same device or when there is insufficient GPU memory.\n",
        "* **Example:** `RuntimeError: CUDA out of memory. Tried to allocate 1.00 GiB (GPU 0; 11.17 GiB total capacity; 8.51 GiB already allocated)`\n",
        "* **Solution:** Free up memory by deleting unnecessary variables with `del`, use smaller batch sizes, or move some tensors to the CPU using `tensor.cpu()`.\n",
        "\n",
        "\n",
        "\n",
        "### **Common Warnings**\n",
        "\n",
        "* **UserWarnings:** PyTorch often issues warnings when it detects potentially problematic operations, such as using deprecated features or inefficient methods.\n",
        "* **Example:** `UserWarning: Using a target size (torch.Size([10, 1])) that is different to the input size (torch.Size([10])) is deprecated.`\n",
        "* **Solution:** Pay attention to warnings and update your code to comply with the latest recommended practices.\n",
        "\n",
        "\n",
        "* **DeprecationWarnings:** These warnings inform you that a particular feature or function will be removed in a future version of PyTorch.\n",
        "* **Solution:** Replace deprecated features with their modern equivalents as suggested in the warning message.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## **Debugging Techniques: Printing Tensors, Using PyTorch Debugger (pdb)**\n",
        "\n",
        "### **Printing Tensors**\n",
        "\n",
        "* **Overview:** One of the simplest yet most effective debugging techniques is printing the values and shapes of tensors at various points in your code. This helps verify that operations are producing the expected results.\n",
        "* **Example:**\n",
        "```python\n",
        "print(f\"Tensor shape: {tensor.shape}\")\n",
        "print(f\"Tensor values: {tensor}\")\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "* **Inspecting Gradients:** You can also print the gradients of tensors after the backward pass to ensure they are being computed correctly.\n",
        "* **Example:** `print(f\"Gradients: {tensor.grad}\")`\n",
        "\n",
        "\n",
        "\n",
        "### **Using PyTorch Debugger (pdb)**\n",
        "\n",
        "* **Overview:** PyTorch can be debugged using Python's built-in `pdb` debugger, which allows you to set breakpoints, step through code, and inspect variables.\n",
        "* **Setting a Breakpoint:** Insert `import pdb; pdb.set_trace()` at the point where you want to start debugging. The execution will pause, allowing you to inspect the environment.\n",
        "* **Example:**\n",
        "```python\n",
        "import pdb\n",
        "def forward_pass(x):\n",
        "    pdb.set_trace() # Start debugging here\n",
        "    y = x + 2\n",
        "    return y\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "* **Common Commands:**\n",
        "* **n (next):** Execute the next line of code.\n",
        "* **c (continue):** Continue execution until the next breakpoint.\n",
        "* **q (quit):** Exit the debugger.\n",
        "* **p variable_name:** Print the value of a variable.\n",
        "\n",
        "\n",
        "\n",
        "## **Handling Numerical Stability Issues: NaNs, Infinities**\n",
        "\n",
        "### **Common Causes of NaNs and Infinities**\n",
        "\n",
        "* **Exploding Gradients:** Gradients that grow exponentially during backpropagation can lead to NaNs or infinities in the model's parameters.\n",
        "* **Solution:** Use gradient clipping to limit the size of the gradients.\n",
        "`torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)`\n",
        "\n",
        "\n",
        "* **Division by Zero:** Certain operations, like division or logarithms, can produce NaNs or infinities when the input is zero or negative.\n",
        "* **Solution:** Add a small epsilon value to the denominator to prevent division by zero.\n",
        "`result = x / (y + 1e-8)`\n",
        "\n",
        "\n",
        "* **Overflow in Exponentials:** Exponential functions can quickly grow to very large values, leading to overflow.\n",
        "* **Solution:** Use the `torch.clamp()` function to limit the range of inputs.\n",
        "`x = torch.clamp(x, min=-10, max=10)`\n",
        "\n",
        "\n",
        "\n",
        "### **Detecting and Handling NaNs and Infinities**\n",
        "\n",
        "* **NaN Detection:** Use the `torch.isnan()` function to detect NaNs in tensors.\n",
        "* **Example:** `if torch.isnan(tensor).any(): print(\"NaN detected!\")`\n",
        "\n",
        "\n",
        "* **Infinity Detection:** Similarly, `torch.isinf()` can be used to detect infinite values.\n",
        "* **Example:** `if torch.isinf(tensor).any(): print(\"Infinity detected!\")`\n",
        "\n",
        "\n",
        "* **Debugging NaNs:** If NaNs or infinities are detected, backtrack through your operations to find where they first appear and modify the operations to ensure numerical stability.\n",
        "\n",
        "\n",
        "## **Profiling and Optimizing PyTorch Code**\n",
        "\n",
        "### **Profiling with torch.profiler**\n",
        "\n",
        "* **Overview:** PyTorch's `torch.profiler` module provides tools for profiling model performance, identifying bottlenecks, and understanding how different parts of your code execute.\n",
        "* **Example:**\n",
        "```python\n",
        "import torch\n",
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "\n",
        "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
        "    with record_function(\"model_inference\"):\n",
        "        model(input_tensor)\n",
        "print(prof.key_averages().table(sort_by=\"cpu_time_total\"))\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "* **Insights:** Profiling can reveal which operations are taking the most time, whether your model is effectively utilizing the GPU, and where you might have inefficiencies in your code.\n",
        "\n",
        "### **Code Optimization Techniques**\n",
        "\n",
        "* **Batching:** Process data in batches rather than individually to take full advantage of GPU parallelism.\n",
        "* **Example:** Instead of processing one image at a time, use a batch of 32 images to maximize GPU utilization.\n",
        "\n",
        "\n",
        "* **Mixed Precision Training:** Use mixed precision training to reduce memory usage and increase computational speed by using 16-bit floating-point numbers where possible.\n",
        "* **Example:**\n",
        "```python\n",
        "model = model.half()\n",
        "input_tensor = input_tensor.half()\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "* **Avoiding Python Loops:** Replace Python loops with PyTorch operations whenever possible to leverage the power of vectorization and GPU acceleration.\n",
        "* **Example:** Instead of looping through tensors to add them, use `tensor.sum(dim=0)` for efficient computation.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zSPPiBpVNw_V"
      }
    }
  ]
}