{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0dFJDLNYoKdUzX2WeiCwt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jhansipothabattula/Machine_Learning/blob/main/Day99.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Self-Training"
      ],
      "metadata": {
        "id": "0EI2Y1H3lP_q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Self-Training**\n",
        "\n",
        "Self-Training is a semi-supervised learning approach that leverages a small labeled dataset alongside a larger unlabeled dataset. The model is initially trained on labeled data, and then it makes predictions on the unlabeled data. The confident predictions (those with high certainty) are then added to the labeled dataset, and the process is repeated to improve the mode"
      ],
      "metadata": {
        "id": "aJHC9fX4lt2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generate a synthetic dataset\n",
        "X, y = make_classification(n_samples=200, n_features=5, random_state=42)\n",
        "X_labeled, X_unlabeled, y_labeled, _ = train_test_split(X, y, test_size=0.7, random_state=42)\n",
        "\n",
        "# Initialize and train the model with labeled data\n",
        "model = RandomForestClassifier(random_state = 42)\n",
        "model.fit(X_labeled, y_labeled)\n",
        "\n",
        "# Perform self-training on unlabeled data\n",
        "for i in range(5):\n",
        "  if X_unlabeled.shape[0] == 0:\n",
        "      print(f\"Iteration {i+1}: No unlabeled data left to process. Exiting self-training loop.\")\n",
        "      break\n",
        "\n",
        "  probs = model.predict_proba(X_unlabeled)\n",
        "  high_confidence_idx = np.where(np.max(probs, axis=1) > 0.9)[0]\n",
        "\n",
        "  # Only proceed if there are high-confidence predictions\n",
        "  if len(high_confidence_idx) > 0:\n",
        "    # Add High-confidence predictions to labeled data\n",
        "    X_labeled = np.vstack((X_labeled, X_unlabeled[high_confidence_idx]))\n",
        "    y_labeled = np.hstack([y_labeled, model.predict(X_unlabeled[high_confidence_idx])])\n",
        "\n",
        "    # Remove confident samples from the unlabeled dataset\n",
        "    X_unlabeled = np.delete(X_unlabeled, high_confidence_idx, axis=0)\n",
        "\n",
        "    # Re-train the model on the expanded labeled dataset\n",
        "    model.fit(X_labeled, y_labeled)\n",
        "    print(f\"Iteration {i+1}: Added {len(high_confidence_idx)} high-confidence samples. Labeled data size: {len(y_labeled)}\")\n",
        "  else:\n",
        "    print(f\"Iteration {i+1}: No high-confidence samples found. Continuing...\")\n",
        "\n",
        "# Final Evaluation on a test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy: \\n\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyFzwJnOmuvH",
        "outputId": "14e5830b-139f-4d95-8b4a-28e6e8c573f3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1: Added 87 high-confidence samples. Labeled data size: 147\n",
            "Iteration 2: Added 16 high-confidence samples. Labeled data size: 163\n",
            "Iteration 3: Added 8 high-confidence samples. Labeled data size: 171\n",
            "Iteration 4: Added 2 high-confidence samples. Labeled data size: 173\n",
            "Iteration 5: No high-confidence samples found. Continuing...\n",
            "Accuracy: \n",
            " 0.875\n"
          ]
        }
      ]
    }
  ]
}