{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlDXEuLTMVgoBUvngKf4tI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jhansipothabattula/Machine_Learning/blob/main/Day26.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-Nearest Neighbors(K-NN)Algorithm"
      ],
      "metadata": {
        "id": "LarKGolbgBRx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Introduction to K-Nearest Neighbors(K-NN) Algorithm and it's Applications**\n",
        "\n",
        "- What is K-Nearest Neighbors?\n",
        "\n",
        "- Key Characterestics\n",
        "\n",
        "  - Instance-Based Learning\n",
        "\n",
        "  - Distance Metric\n",
        "\n",
        "  - Classification\n",
        "\n",
        "  - Regression\n",
        "\n",
        "- Applications\n",
        "\n",
        "  - Image Recognition\n",
        "\n",
        "  - Recommendation Systems\n",
        "\n",
        "  - Medical Diagnosis\n",
        "\n",
        "  - Customer Segmentation"
      ],
      "metadata": {
        "id": "nP4qSNFxgT68"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How K-NN works for Classification and Regression**\n",
        "\n",
        "- step-by-Step process\n",
        "\n",
        "  - Feature Scaling\n",
        "\n",
        "  - Calculate Distances\n",
        "\n",
        "  - Identify k Nearest Neighbors\n",
        "\n",
        "  - Make Predictions\n",
        "\n",
        "    - Classifictaion\n",
        "\n",
        "    - Regression"
      ],
      "metadata": {
        "id": "7OmgK3ydhAz3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Choosing the Optimal value of k**\n",
        "\n",
        "- Choosing k\n",
        "\n",
        "  - Small k\n",
        "\n",
        "    - High sensitivity to noise\n",
        "\n",
        "    - Captures to local variations in data\n",
        "\n",
        "  - Large k\n",
        "\n",
        "    - Smoother decision boundaries but can miss finer details\n",
        "\n",
        "- Common Practices\n",
        "\n",
        "  - Use cross-validation to determine the optimal value of k\n",
        "\n",
        "  - A common starting point is k= root n, where n is the number of training samples"
      ],
      "metadata": {
        "id": "Cia-iThuhl4L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Understanding the Model's Limitations**\n",
        "\n",
        "- Compuatationally Expensive\n",
        "\n",
        "  - Predictions require distance computation for all training samples\n",
        "\n",
        "- Feature Scaling Dependence\n",
        "\n",
        "  - Requires proper scaling to avoid feature dominance\n",
        "\n",
        "- Not Robust to Imbalanced Data\n",
        "\n",
        "  - Classes with more samples can dominate predictions"
      ],
      "metadata": {
        "id": "IJIqlFLKijNF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement k-NN for a Classification task, experimenting with different values of k**"
      ],
      "metadata": {
        "id": "ve1_l-37jQjj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression # Changed from LinearRegression to LogisticRegression\n",
        "\n",
        "# Load Iris dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic regression model\n",
        "log_reg = LogisticRegression(max_iter = 200) # Corrected parameter name from max_iters to max_iter\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Predict using Logistic Regression\n",
        "y_pred_lr = log_reg.predict(X_test)\n",
        "\n",
        "# Evaluate Logistic Regression\n",
        "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
        "print(\"Logistic Regression Accuracy: \\n\", accuracy_lr)\n",
        "\n",
        "# Evaluate k-NN\n",
        "best_k = 5\n",
        "knn = KNeighborsClassifier(n_neighbors=best_k)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
        "print(f\"K-NN Accuracy k={best_k}: \\n\", accuracy_knn)\n",
        "\n",
        "# Detailed Comparison\n",
        "print(\"Logistic Regression Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_lr))\n",
        "\n",
        "print(\"K-NN Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_knn))\n",
        "\n",
        "# Experimenting with different values of k\n",
        "for k in range(1, 11):\n",
        "  # Initialize k-NN model\n",
        "  knnn = KNeighborsClassifier(n_neighbors=k)\n",
        "  knnn.fit(X_train, y_train)\n",
        "\n",
        "  # Make predictions on test data\n",
        "  y_pred = knnn.predict(X_test)\n",
        "\n",
        "  # Evaluate the model perfomance\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  print(f\"Accuracy for k={k}: {accuracy: .2f}\")\n",
        "  print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xkrgp5CMjdvh",
        "outputId": "94723600-3e5f-434f-e3f1-e09bae1a0782"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: \n",
            " 1.0\n",
            "K-NN Accuracy k=5: \n",
            " 1.0\n",
            "Logistic Regression Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n",
            "K-NN Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n",
            "Accuracy for k=1:  1.00\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n",
            "Accuracy for k=2:  1.00\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n",
            "Accuracy for k=3:  1.00\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n",
            "Accuracy for k=4:  1.00\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n",
            "Accuracy for k=5:  1.00\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n",
            "Accuracy for k=6:  1.00\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n",
            "Accuracy for k=7:  1.00\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n",
            "Accuracy for k=8:  1.00\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n",
            "Accuracy for k=9:  1.00\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n",
            "Accuracy for k=10:  1.00\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n"
          ]
        }
      ]
    }
  ]
}