{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+t9f2AQdOvdmtorCFROnS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jhansipothabattula/Machine_Learning/blob/main/Day106.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recurrent Neural Networks(RNNs)"
      ],
      "metadata": {
        "id": "ojBWLxYHROIr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Recurrent Neural Networks (RNNs)**\n",
        "\n",
        "Recurrent Neural Networks (RNNs) are neural networks designed for sequential data, such as time series, language, or speech. RNNs have connections that form cycles, allowing them to retain information from previous steps in the sequence. This makes RNNs well-suited for tasks like text generation, language modeling, and time series forecasting. A common variant, Long Short-Term Memory (LSTM), helps to address the issue of long-term dependency"
      ],
      "metadata": {
        "id": "ROiIQO62RigN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "\n",
        "# Load and preprocess the IMDB dataset\n",
        "max_features = 10000  # Number of words to consider as features\n",
        "max_len = 500         # Cut off reviews after 500 words\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "# Pad sequences to ensure uniform input length\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=max_len)\n",
        "\n",
        "# Build the RNN model\n",
        "model = models.Sequential([\n",
        "    # Embedding layer to turn integers into dense vectors\n",
        "    layers.Embedding(max_features, 32, input_length = max_len),\n",
        "\n",
        "    # Simple RNN layer with 32 hidden units\n",
        "    layers.SimpleRNN(32),\n",
        "\n",
        "    # Output layer for binary classification (positive/negative sentiment)\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile and train the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_Kuk-I_R7mj",
        "outputId": "ed29b639-f5e6-40a2-dc33-efb50b47feef"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 123ms/step - accuracy: 0.5478 - loss: 0.6828 - val_accuracy: 0.7178 - val_loss: 0.5547\n",
            "Epoch 2/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 121ms/step - accuracy: 0.7839 - loss: 0.4644 - val_accuracy: 0.8064 - val_loss: 0.4384\n",
            "Epoch 3/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 119ms/step - accuracy: 0.8897 - loss: 0.2776 - val_accuracy: 0.8248 - val_loss: 0.4150\n",
            "Epoch 4/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 129ms/step - accuracy: 0.9509 - loss: 0.1537 - val_accuracy: 0.8352 - val_loss: 0.4369\n",
            "Epoch 5/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 128ms/step - accuracy: 0.9837 - loss: 0.0643 - val_accuracy: 0.8236 - val_loss: 0.5263\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - accuracy: 0.8198 - loss: 0.5484\n",
            "Test Accuracy: 0.8214\n"
          ]
        }
      ]
    }
  ]
}